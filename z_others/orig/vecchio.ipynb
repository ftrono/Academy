{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "corpus_file = \"../data/sample_corpus.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CORPUS PROCESSING:\n",
    "#accepts: directory of dataset file, vocabulary as dict (optional).\n",
    "#returns: corpus as list of tokens, length of longest sentence.\n",
    "def corpus_prepare(fdir, voc=None):\n",
    "  f = open(fdir, \"r\")\n",
    "  corpus = []\n",
    "  l = 0\n",
    "  longest = 0\n",
    "  print(\"Preparing corpus...\")\n",
    "\n",
    "  for aline in f:\n",
    "    aline = aline.strip()\n",
    "    tokens = aline.split()\n",
    "    corpus.append('')\n",
    "    l = 1\n",
    "    for tok in tokens:\n",
    "      #if voc, align corpus to vocabulary (replace OOV):\n",
    "      if voc:\n",
    "        if tok not in voc.keys():\n",
    "          corpus.append('')\n",
    "        else:\n",
    "          corpus.append(tok)\n",
    "      else:\n",
    "        corpus.append(tok)\n",
    "      l = l+1\n",
    "    if l > longest:\n",
    "      longest = l\n",
    "    corpus.append('')\n",
    "  \n",
    "  f.close()\n",
    "  return corpus, longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) Vocabulary extractor (tokens and integers):\n",
    "#accepts: corpus.\n",
    "#returns: vocabulary in dict format (words2ind), with tokens as keys and integers as values.\n",
    "def get_vocab(corpus):\n",
    "  #1) PRODUCE VOC & W2I:\n",
    "  vocab = {}\n",
    "  print(\"Extracting vocabulary from corpus...\")\n",
    "  #append default toks:\n",
    "  vocab[''] = 0\n",
    "  vocab[''] = 1\n",
    "  vocab[''] = 2\n",
    "  vocab[''] = 3\n",
    "  i = 4\n",
    "  for tok in corpus:\n",
    "    if tok not in vocab.keys():\n",
    "      vocab[tok] = i\n",
    "      i = i+1\n",
    "\n",
    "  #2: PRODUCE I2W:\n",
    "  i2w = {}\n",
    "\n",
    "  for k, v in vocab.items():\n",
    "    i2w[v] = k\n",
    "\n",
    "  return vocab, i2w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts the full dataset to integers vector on the basis of the vocabulary:\n",
    "#accepts: vocabulary as dict, boolean to set the reading source (True for file, False for corpus), then either directory of dataset file or corpus to convert.\n",
    "#returns: list of integers corresponding to vocabulary word indices.\n",
    "def vectorize(voc, fromfile, fdir=None, corpus=None):\n",
    "  \n",
    "  #mode: read from input file:\n",
    "  if fromfile == True:\n",
    "    #if no file provided:\n",
    "    if not fdir:\n",
    "      return -1\n",
    "    else:\n",
    "      #read file:\n",
    "      corpus, longest = corpus_prepare(fdir, voc)\n",
    "  else:\n",
    "    #mode: read from input corpus:\n",
    "    if not corpus:\n",
    "      return -1\n",
    "\n",
    "  #vectorize:\n",
    "  vectd = []\n",
    "  i = 0\n",
    "\n",
    "  for tok in corpus:\n",
    "    if tok not in voc.keys():\n",
    "      #replace with :\n",
    "      vectd.append(1)\n",
    "    else:\n",
    "      vectd.append(voc[tok])\n",
    "\n",
    "  if fromfile == True: \n",
    "    return vectd, longest\n",
    "  else:\n",
    "    return vectd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing corpus...\n",
      "['', 'who', \"'s\", 'in', 'star', 'wars', 'episode', 'four', '', '']\n",
      "23\n",
      "Extracting vocabulary from corpus...\n",
      "[('', 3), ('who', 4), (\"'s\", 5), ('in', 6), ('star', 7), ('wars', 8), ('episode', 9), ('four', 10), ('was', 11), ('Apollo', 12)]\n",
      "1040\n",
      "[(3, ''), (4, 'who'), (5, \"'s\"), (6, 'in'), (7, 'star'), (8, 'wars'), (9, 'episode'), (10, 'four'), (11, 'was'), (12, 'Apollo')]\n"
     ]
    }
   ],
   "source": [
    "#MAIN:\n",
    "trn_corpus, trn_sl = corpus_prepare(corpus_file)\n",
    "print(trn_corpus[0:10])\n",
    "print(trn_sl)\n",
    "\n",
    "#voc is also the w2i vector:\n",
    "voc, i2w = get_vocab(trn_corpus)\n",
    "\n",
    "voc_w = list(voc.keys())\n",
    "voc_i = list(voc.values())\n",
    "vocl = len(voc_i)\n",
    "\n",
    "print(list(voc.items())[0:10])\n",
    "print(vocl)\n",
    "print(list(i2w.items())[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vector converter from integers to tokens:\n",
    "#accepts: vector of integers and i2w dict.\n",
    "#returns: converted vector of tokens.\n",
    "def deindexer(vect, i2w):\n",
    "  #Init:\n",
    "  conv = []\n",
    "\n",
    "  for i in vect:\n",
    "    conv.append(i2w[i])\n",
    "  \n",
    "  return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5, 6, 7, 8, 9, 10, 3, 3, 4, 11, 6, 12, 13, 3, 3, 4, 11, 12, 13, 5, 14, 3, 3, 15, 16, 17, 18, 19, 14, 20, 21, 22, 23, 13, 3, 3, 24, 25, 26, 27, 28, 29, 18, 19, 14, 20, 21, 22]\n",
      "['', 'who', \"'s\", 'in', 'star', 'wars', 'episode', 'four', '', '', 'who', 'was', 'in', 'Apollo', 'thirteen', '', '', 'who', 'was', 'Apollo', 'thirteen', \"'s\", 'cast', '', '', 'search', 'for', 'information', 'about', 'the', 'cast', 'and', 'crew', 'of', 'appolo', 'thirteen', '', '', 'i', 'would', 'like', 'to', 'know', 'more', 'about', 'the', 'cast', 'and', 'crew', 'of']\n",
      "23\n",
      "MAX SENTENCE LENGTH: 23\n"
     ]
    }
   ],
   "source": [
    "trn_vect = vectorize(voc, False, corpus=trn_corpus)\n",
    "print(trn_vect[0:50])\n",
    "\n",
    "trn_w = deindexer(trn_vect, i2w)\n",
    "print(trn_w[0:50])\n",
    "\n",
    "#MAX SEQUENCE SIZE:\n",
    "print(trn_sl)\n",
    "print(\"MAX SENTENCE LENGTH: {}\".format(trn_sl))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
